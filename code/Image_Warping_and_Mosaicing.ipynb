{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CG-ydemPue0V"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial import Delaunay\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.draw import polygon, polygon2mask\n",
        "from scipy.interpolate import griddata\n",
        "import skimage.io as io\n",
        "import skimage as sk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "stadium1 = io.imread('images/stadium_resized_1.png')\n",
        "stadium2 = io.imread('images/stadium_resized_2.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open(\"stadidum_resized_1_stadium_resized_2.json\")\n",
        "json_data = json.load(f)\n",
        "im1_points = np.array(json_data['im1Points'])\n",
        "im2_points = np.array(json_data['im2Points']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P9BnY2lIuwSZ"
      },
      "outputs": [],
      "source": [
        "def computeH(im1_points, im2_points):\n",
        "  A = []\n",
        "  B = []\n",
        "  for i in range(len(im1_points)):\n",
        "    p1 = im1_points[i]\n",
        "    p2 = im2_points[i] \n",
        "    A.append([p1[0], p1[1], 1, 0, 0, 0, -p1[0] * p2[0], -p1[1] * p2[0]])\n",
        "    A.append([0, 0, 0, p1[0], p1[1], 1, -p1[0] * p2[1], -p1[1] * p2[1]])\n",
        "    B.append(p2[0])\n",
        "    B.append(p2[1])\n",
        "  A = np.asarray(A)\n",
        "  B = np.asarray(B)\n",
        "  H_flatten = np.linalg.lstsq(A, B)[0]\n",
        "  H_flatten = np.asarray(H_flatten.tolist() + [1])\n",
        "  return np.reshape(H_flatten, (3, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UXITZ7kmwxCF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lf/lddj8h6s3m3g8fkfp14cq4bw0000gn/T/ipykernel_71220/628019653.py:13: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  H_flatten = np.linalg.lstsq(A, B)[0]\n"
          ]
        }
      ],
      "source": [
        "H = computeH(im1_points, im2_points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize(im):\n",
        "    return (im - np.amin(im)) / (np.amax(im) - np.amin(im))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def createGrid(xmin, xmax,ymin,ymax):\n",
        "    x_matrix = np.repeat(np.arange(xmin, xmax), (ymax - ymin)).reshape(-1, (ymax - ymin)).T\n",
        "    y_matrix = np.repeat(np.arange(ymin, ymax), (xmax - xmin)).reshape((ymax - ymin), (xmax - xmin))\n",
        "    return x_matrix, y_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def warpImage(im,H):\n",
        "    corners = [np.array([0,0, 1]),np.array([0,im.shape[0]-1, 1]),np.array([im.shape[1]-1,0, 1]),np.array([im.shape[1]-1,im.shape[0]-1, 1])]\n",
        "    warped_corners = [ corner @ H.T for corner in corners] \n",
        "    min_x, min_y = np.min(warped_corners, axis=0)[:2]\n",
        "    min_x_index, min_y_index = 0, 0 \n",
        "    min_x_sofar, min_y_sofar = warped_corners[0][0], warped_corners[0][1]\n",
        "    max_x_index, max_y_index = 0, 0\n",
        "    max_x_sofar, max_y_sofar = warped_corners[0][0], warped_corners[0][1]\n",
        "    for i in range(len(warped_corners)):\n",
        "        if warped_corners[i][0] < min_x_sofar:\n",
        "            min_x_index = i\n",
        "            min_x_sofar = warped_corners[i][0]\n",
        "        if warped_corners[i][0] > max_x_sofar:\n",
        "            max_x_index = i\n",
        "            max_x_sofar = warped_corners[i][0]\n",
        "        if warped_corners[i][1] < min_y_sofar:\n",
        "            min_y_index = i\n",
        "            min_y_sofar = warped_corners[i][1]\n",
        "        if warped_corners[i][1] > max_y_sofar:\n",
        "            max_y_index = i\n",
        "            max_y_sofar = warped_corners[i][1]\n",
        "    min_x, min_y = np.floor(min_x / warped_corners[min_x_index][2]), np.floor(min_y / warped_corners[min_y_index][2])\n",
        "    max_x, max_y = np.max(warped_corners, axis=0)[:2]\n",
        "    max_x, max_y = np.ceil(max_x / warped_corners[max_x_index][2]), np.ceil(max_y / warped_corners[max_y_index][2])\n",
        "    warped_corners = np.asanyarray(warped_corners)\n",
        "    new_width = int(abs(min_x - max_x))\n",
        "    new_height = int(abs(min_y - max_y)) \n",
        "    x_coords, y_coords = createGrid(int(min_x), int(max_x), int(min_y), int(max_y))\n",
        "    coords = np.stack((x_coords, y_coords, np.ones(x_coords.shape)), axis = 2)\n",
        "    coords = coords.reshape((x_coords.size, 3))\n",
        "    inv_warp_x, inv_warp_y, _ = coords.T\n",
        "    img_gridx,img_gridy = createGrid(0, im.shape[1], 0, im.shape[0])\n",
        "    img_coords = np.stack((img_gridx, img_gridy, np.ones(img_gridx.shape)), axis = 2)\n",
        "    img_coords = img_coords.reshape((img_gridx.size, 3))\n",
        "    img_x, img_y, _ = img_coords.T \n",
        "    interpret_values = [] \n",
        "    for i in range(im.shape[2]):\n",
        "        temp = griddata((img_x, img_y), im[:, :, i].flatten(), (inv_warp_x, inv_warp_y), method='linear', fill_value=0)\n",
        "        interpret_values.append(temp.reshape([new_height, new_width])) \n",
        "    return np.stack(interpret_values, axis = 2) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_image(im):\n",
        "    return (im - np.amin(im)) / (np.amax(im) - np.amin(im))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_to_list_of_coords(xs, ys):\n",
        "    gridx, gridy = np.meshgrid(xs, ys)\n",
        "    stacked = np.stack((gridx, gridy, np.ones(gridx.shape)), axis = 2)\n",
        "    flat_stax = stacked.reshape((gridx.size, 3))\n",
        "    return flat_stax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image Rectification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "rectify_im1 = io.imread('images/rectify_im1.png')\n",
        "rectify_im2 = io.imread('images/rectify_im2.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "rectify_im3 = io.imread('images/rectify_im3.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open(\"rectify_im1_rectify_im1.json\")\n",
        "json_data = json.load(f) \n",
        "rectify_im1_points = np.array(json_data['im1Points'])\n",
        "width = abs(np.min(rectify_im1_points, axis=0)[0] - np.max(rectify_im1_points, axis=0)[0])\n",
        "height = abs(np.min(rectify_im1_points, axis=0)[1] - np.max(rectify_im1_points, axis=0)[1])\n",
        "starting_point = np.min(rectify_im1_points, axis=0)[:2]\n",
        "im1_rectified_points = np.asarray([starting_point, [starting_point[0] + width, starting_point[1]], [starting_point[0] + width, starting_point[1] + height], [starting_point[0], starting_point[1] + height]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open(\"rectify_im3_rectify_im3.json\")\n",
        "json_data = json.load(f) \n",
        "rectify_im3_points = np.array(json_data['im1Points'])\n",
        "width = abs(np.min(rectify_im3_points, axis=0)[0] - np.max(rectify_im3_points, axis=0)[0])\n",
        "height = abs(np.min(rectify_im3_points, axis=0)[1] - np.max(rectify_im3_points, axis=0)[1])\n",
        "starting_point = np.min(rectify_im3_points, axis=0)[:2]\n",
        "im3_rectified_points = np.asarray([starting_point, [starting_point[0] + width, starting_point[1]], [starting_point[0] + width, starting_point[1] + height], [starting_point[0], starting_point[1] + height]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Blend the images into a mosaic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open(\"ihouse1_ihouse2.json\")\n",
        "json_data = json.load(f)\n",
        "ihouse1 = io.imread('images/ihouse1.png')\n",
        "ihouse2 = io.imread('images/ihouse2.png')\n",
        "ihouse1_points = np.array(json_data['im1Points'])\n",
        "ihouse2_points = np.array(json_data['im2Points']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lf/lddj8h6s3m3g8fkfp14cq4bw0000gn/T/ipykernel_71220/628019653.py:13: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  H_flatten = np.linalg.lstsq(A, B)[0]\n"
          ]
        }
      ],
      "source": [
        "ihouseH = computeH(ihouse1_points, ihouse2_points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "ihousewarped = warp_image(ihouse1,ihouseH, \"linear\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lf/lddj8h6s3m3g8fkfp14cq4bw0000gn/T/ipykernel_71220/1012367921.py:2: RuntimeWarning: invalid value encountered in divide\n",
            "  return (im - np.amin(im)) / (np.amax(im) - np.amin(im))\n"
          ]
        }
      ],
      "source": [
        "ihousewarped = normalize_image(ihousewarped[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.transform as sktr\n",
        "\n",
        "def get_points(im1, im2):\n",
        "    print('Please select 2 points in each image for alignment.')\n",
        "    plt.imshow(im1)\n",
        "    p1, p2 = plt.ginput(2)\n",
        "    plt.close()\n",
        "    plt.imshow(im2)\n",
        "    p3, p4 = plt.ginput(2)\n",
        "    plt.close()\n",
        "    return (p1, p2, p3, p4)\n",
        "\n",
        "def recenter(im, r, c):\n",
        "    R, C, _ = im.shape\n",
        "    rpad = (int) (np.abs(2*r+1 - R))\n",
        "    cpad = (int) (np.abs(2*c+1 - C))\n",
        "    return np.pad(\n",
        "        im, [(0 if r > (R-1)/2 else rpad, 0 if r < (R-1)/2 else rpad),\n",
        "             (0 if c > (C-1)/2 else cpad, 0 if c < (C-1)/2 else cpad),\n",
        "             (0, 0)], 'constant')\n",
        "\n",
        "def find_centers(p1, p2):\n",
        "    cx = np.round(np.mean([p1[0], p2[0]]))\n",
        "    cy = np.round(np.mean([p1[1], p2[1]]))\n",
        "    return cx, cy\n",
        "\n",
        "def align_image_centers(im1, im2, pts):\n",
        "    p1, p2, p3, p4 = pts\n",
        "    h1, w1, b1 = im1.shape\n",
        "    h2, w2, b2 = im2.shape\n",
        "\n",
        "    cx1, cy1 = find_centers(p1, p2)\n",
        "    cx2, cy2 = find_centers(p3, p4)\n",
        "\n",
        "    im1 = recenter(im1, cy1, cx1)\n",
        "    im2 = recenter(im2, cy2, cx2)\n",
        "    return im1, im2\n",
        "\n",
        "def rescale_images(im1, im2, pts):\n",
        "    p1, p2, p3, p4 = pts\n",
        "    len1 = np.sqrt((p2[1] - p1[1])**2 + (p2[0] - p1[0])**2)\n",
        "    len2 = np.sqrt((p4[1] - p3[1])**2 + (p4[0] - p3[0])**2)\n",
        "    dscale = len2/len1\n",
        "    if dscale < 1:\n",
        "        im1 = sktr.rescale(im1, (dscale, dscale, 1))\n",
        "    else:\n",
        "        im2 = sktr.rescale(im2, (1./dscale, 1./dscale, 1))\n",
        "    return im1, im2\n",
        "\n",
        "def rotate_im1(im1, im2, pts):\n",
        "    p1, p2, p3, p4 = pts\n",
        "    theta1 = math.atan2(-(p2[1] - p1[1]), (p2[0] - p1[0]))\n",
        "    theta2 = math.atan2(-(p4[1] - p3[1]), (p4[0] - p3[0]))\n",
        "    dtheta = theta2 - theta1\n",
        "    im1 = sktr.rotate(im1, dtheta*180/np.pi)\n",
        "    return im1, dtheta\n",
        "\n",
        "def match_img_size(im1, im2):\n",
        "    # Make images the same size\n",
        "    h1, w1, c1 = im1.shape\n",
        "    h2, w2, c2 = im2.shape\n",
        "    if h1 < h2:\n",
        "        im2 = im2[int(np.floor((h2-h1)/2.)) : -int(np.ceil((h2-h1)/2.)), :, :]\n",
        "    elif h1 > h2:\n",
        "        im1 = im1[int(np.floor((h1-h2)/2.)) : -int(np.ceil((h1-h2)/2.)), :, :]\n",
        "    if w1 < w2:\n",
        "        im2 = im2[:, int(np.floor((w2-w1)/2.)) : -int(np.ceil((w2-w1)/2.)), :]\n",
        "    elif w1 > w2:\n",
        "        im1 = im1[:, int(np.floor((w1-w2)/2.)) : -int(np.ceil((w1-w2)/2.)), :]\n",
        "    assert im1.shape == im2.shape\n",
        "    return im1, im2\n",
        "\n",
        "def align_images(im1, im2):\n",
        "    pts = get_points(im1, im2)\n",
        "    im1, im2 = align_image_centers(im1, im2, pts)\n",
        "    im1, im2 = rescale_images(im1, im2, pts)\n",
        "    im1, angle = rotate_im1(im1, im2, pts)\n",
        "    im1, im2 = match_img_size(im1, im2)\n",
        "    return im1, im2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "import PyQt5\n",
        "%matplotlib qt5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select 2 points in each image for alignment.\n"
          ]
        }
      ],
      "source": [
        "aligned_ihouse1, aligned_ihouse2 = align_images(ihousewarped, ihouse2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done with color 0\n",
            "done with color 1\n",
            "done with color 2\n",
            "done with color 3\n"
          ]
        }
      ],
      "source": [
        "rectify_im1_warped = warp_image(rectify_im1, rectify_im1_H, 'linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.signal import convolve2d\n",
        "def create_gaussian_stacks(im, N):\n",
        "    image_pyramids = [] \n",
        "    temp = np.array([im[:,:,0], im[:,:,1], im[:,:,2]])\n",
        "    image_pyramids.append(im)\n",
        "    size, sigma = 6, 1\n",
        "    while N > 0:\n",
        "        GaussianFilter = np.outer(cv2.getGaussianKernel(size, sigma), cv2.getGaussianKernel(size, sigma))\n",
        "        im_blurred_r = convolve2d(temp[0], GaussianFilter, \"same\")\n",
        "        im_blurred_g = convolve2d(temp[1], GaussianFilter, \"same\")\n",
        "        im_blurred_b = convolve2d(temp[2], GaussianFilter, \"same\")\n",
        "        im_blurred = np.stack((im_blurred_r, im_blurred_g, im_blurred_b), axis=2)\n",
        "        image_pyramids.append(im_blurred)\n",
        "        temp = [im_blurred_r, im_blurred_g, im_blurred_b]\n",
        "        size, sigma = size * 2, sigma * 2\n",
        "        N -= 1 \n",
        "    return np.array(image_pyramids)\n",
        "\n",
        "def create_laplacian_stacks(im, N):\n",
        "    gaussian_pyramids = create_gaussian_stacks(im, N)\n",
        "    laplacian_pyramids = []\n",
        "    for i in range(1, len(gaussian_pyramids)-1):\n",
        "        laplacian_pyramids.append(gaussian_pyramids[i] - gaussian_pyramids[i-1])\n",
        "    laplacian_pyramids.append(gaussian_pyramids[-1])\n",
        "    return np.array(laplacian_pyramids) \n",
        "\n",
        "def create_gaussian_masks(mask, N, sigma):\n",
        "    temp = [mask[:, :, 0], mask[:, :, 1], mask[:, :, 2]]\n",
        "    mask_stacks = [mask]\n",
        "    while N > 1:\n",
        "        size = sigma * 6\n",
        "        GaussianFilter = np.outer(cv2.getGaussianKernel(size, sigma), cv2.getGaussianKernel(size, sigma))\n",
        "        mask_r = convolve2d(temp[0], GaussianFilter, \"same\")\n",
        "        mask_g = convolve2d(temp[1], GaussianFilter, \"same\")\n",
        "        mask_b = convolve2d(temp[2], GaussianFilter, \"same\")\n",
        "        mask_stacked = np.stack((mask_r, mask_g, mask_b), axis=2)\n",
        "        mask_stacks.append(mask_stacked)\n",
        "        temp = [mask_r, mask_g, mask_b]\n",
        "        sigma *= 2\n",
        "        N -= 1 \n",
        "    return np.array(mask_stacks) \n",
        "\n",
        "def combine_laplacian_stacks(im1, im2, N, binary_mask_right):\n",
        "    laplacian_stack1 = create_laplacian_stacks(im1, N)\n",
        "    laplacian_stack2 = create_laplacian_stacks(im2, N)\n",
        "    mask_stack = create_gaussian_masks(binary_mask_right, N, 1)\n",
        "    combined_stack = []\n",
        "    for i in range(len(laplacian_stack1)):\n",
        "        left = laplacian_stack1[i] * mask_stack[i]\n",
        "        right = (np.ones(mask_stack[i].shape) - mask_stack[i]) * laplacian_stack2[i]\n",
        "        combined_stack.append(left + right)\n",
        "    return np.sum(combined_stack, axis = 0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select 2 points in each image for alignment.\n"
          ]
        }
      ],
      "source": [
        "ihouse1_aligned, ihouse2_aligned = align_images(ihouse1_warped, ihouse2_warped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select 2 points in each image for alignment.\n"
          ]
        }
      ],
      "source": [
        "ihouse1_for_stitch = io.imread('images/ihouse1_aligned.png')\n",
        "ihouse2_for_stitch = io.imread('images/ihouse2_aligned.png')\n",
        "ihouse1_for_stitch, ihouse2_for_stitch = align_images(ihouse1_for_stitch, ihouse2_for_stitch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_gaussian_stacks(im, N, sigma):\n",
        "    image_pyramids = [] \n",
        "    temp = np.array([im[:,:,0], im[:,:,1], im[:,:,2]])\n",
        "    image_pyramids.append(im) \n",
        "    size = sigma * 6\n",
        "    while N > 0:\n",
        "        GaussianFilter = np.outer(cv2.getGaussianKernel(size, sigma), cv2.getGaussianKernel(size, sigma))\n",
        "        im_blurred_r = convolve2d(temp[0], GaussianFilter, \"same\", boundary=\"symm\")\n",
        "        im_blurred_g = convolve2d(temp[1], GaussianFilter, \"same\", boundary=\"symm\")\n",
        "        im_blurred_b = convolve2d(temp[2], GaussianFilter, \"same\", boundary=\"symm\")\n",
        "        im_blurred = np.stack((im_blurred_r, im_blurred_g, im_blurred_b), axis=2)\n",
        "        image_pyramids.append(im_blurred)\n",
        "        temp = [im_blurred_r, im_blurred_g, im_blurred_b]\n",
        "        size, sigma = size * 2, sigma * 2 \n",
        "        N -= 1 \n",
        "    return np.array(image_pyramids)\n",
        "\n",
        "def create_laplacian_stacks(im, N):\n",
        "    gaussian_pyramids = create_gaussian_stacks(im, N, 1)\n",
        "    laplacian_pyramids = []\n",
        "    for i in range(len(gaussian_pyramids)-2):\n",
        "        laplacian_pyramids.append(gaussian_pyramids[i] - gaussian_pyramids[i+1])\n",
        "    laplacian_pyramids.append(gaussian_pyramids[-1])\n",
        "    return np.array(laplacian_pyramids) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {},
      "outputs": [],
      "source": [
        "def combine_laplacian_stacks(im1, im2, N, binary_mask_right):\n",
        "    laplacian_stack1 = create_laplacian_stacks(im1, N)\n",
        "    laplacian_stack2 = create_laplacian_stacks(im2, N)\n",
        "    mask_stack = create_gaussian_masks(binary_mask_right, N, 5)\n",
        "    combined_stack = []\n",
        "    for i in range(len(laplacian_stack1)):\n",
        "        left = laplacian_stack1[i] * mask_stack[i]\n",
        "        right = (np.ones(mask_stack[i].shape) - mask_stack[i]) * laplacian_stack2[i]\n",
        "        combined_stack.append(left + right)\n",
        "    return np.sum(combined_stack, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 374,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "738\n"
          ]
        }
      ],
      "source": [
        "f = open (\"ihouse1_aligned_ihouse2_aligned.json\")\n",
        "json_data = json.load(f)\n",
        "ihouse1_for_stitch_points = np.array(json_data['im1Points'])\n",
        "ihouse2_for_stitch_points = np.array(json_data['im2Points'])\n",
        "# mask = np.array(polygon(ihouse1_for_stitch_points[:, 0], ihouse1_for_stitch_points[:, 1])).T\n",
        "# io.imshow(normalize_image(mask))\n",
        "# plt.show()  \n",
        "mask1 = polygon2mask(ihouse1_for_stitch.shape[:2], ihouse1_for_stitch_points[:, ::-1]).astype(np.uint8)\n",
        "mask2 = polygon2mask(ihouse2_for_stitch.shape[:2], ihouse2_for_stitch_points[:, ::-1]).astype(np.uint8)\n",
        "mask1_width = mask1.shape[1]\n",
        "gray_value = 0.8\n",
        "height = mask1.shape[0] \n",
        "width = mask1.shape[1]\n",
        "print(width)\n",
        "gray_mask_left = np.full((height, width*4//9), gray_value)\n",
        "black_mask_right = np.zeros((height, width*5//9), dtype=np.uint8)\n",
        "gray_mask_right = np.full((height, width*5//9), gray_value)\n",
        "black_mask_left = np.zeros((height, width*4//9), dtype=np.uint8)\n",
        "gray_right = np.concatenate((black_mask_left, gray_mask_right), axis=1)\n",
        "gray_left = np.concatenate((gray_mask_left, black_mask_right), axis=1)\n",
        "mask1_grayed = normalize_image(mask1)  \n",
        "mask1_grayed = np.where(mask1_grayed == 1.0, 0.4444444444444445, mask1_grayed)\n",
        "mask1_grayed = np.where(mask1_grayed == 0.0, 1.0, mask1_grayed)\n",
        "mask1_grayed = np.where(mask1_grayed == 0.4444444444444445, 0.0, mask1_grayed)\n",
        "mask2_grayed = normalize_image(mask2)   \n",
        "mask2_grayed = np.where(mask2_grayed == 1.0, 0.4444444444444445, mask2_grayed)\n",
        "mask2_grayed = np.where(mask2_grayed == 0.0, 1.0, mask2_grayed)\n",
        "mask2_grayed = np.where(mask2_grayed == 0.4444444444444445, 0.0, mask2_grayed) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 375,
      "metadata": {},
      "outputs": [],
      "source": [
        "ihouse1_for_stitch_resized = ihouse1_for_stitch[:, :, :3]\n",
        "ihouse2_for_stitch_resized = ihouse2_for_stitch[:, :, :3]\n",
        "mask1_grayed_converted = cv2.convertScaleAbs(mask1_grayed, alpha=255)\n",
        "mask1_grayed_resized = cv2.cvtColor(mask1_grayed_converted, cv2.COLOR_GRAY2BGR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 376,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask2_grayed_converted = cv2.convertScaleAbs(mask2_grayed, alpha=255)\n",
        "mask2_grayed_resized = cv2.cvtColor(mask2_grayed_converted, cv2.COLOR_GRAY2BGR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 391,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(396, 738, 3)"
            ]
          },
          "execution_count": 391,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mask1_grayed_finalized = mask1_grayed_resized /  255.0\n",
        "mask1_grayed_finalized = 1 - mask1_grayed_finalized\n",
        "mask1_grayed_finalized .shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask2_grayed_finalized = mask2_grayed_resized / 255.0\n",
        "mask2_grayed_finalized = 1 - mask2_grayed_finalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 425,
      "metadata": {},
      "outputs": [],
      "source": [
        "overlap = cv2.bitwise_and(mask1_grayed_finalized, mask2_grayed_finalized)\n",
        "overlap_grayed = np.where(overlap == 1, 0.4, overlap)\n",
        "overlap_blurred = cv2.GaussianBlur(overlap_grayed, (5, 5), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 440,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 440,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mask_with_overlap = normalize_image(mask1_grayed_finalized - overlap_grayed)\n",
        "mask_with_overlap_blurred = cv2.GaussianBlur(mask_with_overlap, (5, 5), 0)\n",
        "mask_with_overlap_blurred.shape == mask1_grayed_finalized.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 437,
      "metadata": {},
      "outputs": [],
      "source": [
        "io.imshow(mask_with_overlap_blurred)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 370,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_combined = normalize_image(mask2_grayed_finalized + mask1_grayed_finalized)\n",
        "# mask_combined = np.where(mask_combined != 0.7784313725490196, 0.0, mask_combined)\n",
        "# # mask_combined = np.where(mask_combined == 0.6784313725490196, 0.9, mask_combined)\n",
        "# # mask_combined = np.where(mask_combined != 0.9, 0.0, mask_combined)\n",
        "io.imshow(normalize_image(mask_combined))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {},
      "outputs": [],
      "source": [
        "io.imshow(normalize_image(mask2_grayed_finalized))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 379,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_combined_blurred = cv2.GaussianBlur(mask_combined, (5, 5), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 380,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_combined_finalized = normalize_image(mask_combined_blurred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 404,
      "metadata": {},
      "outputs": [],
      "source": [
        "io.imshow(normalize_image(mask_combined_finalized))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 400,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 400,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mask_combined_finalized.shape == mask1_grayed_finalized.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 405,
      "metadata": {},
      "outputs": [],
      "source": [
        "io.imshow(normalize_image(mask1_grayed_finalized))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 441,
      "metadata": {},
      "outputs": [],
      "source": [
        "ihouse_combined = combine_laplacian_stacks(ihouse1_for_stitch_resized, ihouse2_for_stitch_resized, 5, mask_with_overlap_blurred)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 442,
      "metadata": {},
      "outputs": [],
      "source": [
        "io.imshow(normalize_image(ihouse_combined))\n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open (\"images/room1_room2.json\")\n",
        "json_data = json.load(f)\n",
        "ihouse1_for_stitch_points = np.array(json_data['im1Points'])\n",
        "ihouse2_for_stitch_points = np.array(json_data['im2Points'])\n",
        "# mask = np.array(polygon(ihouse1_for_stitch_points[:, 0], ihouse1_for_stitch_points[:, 1])).T\n",
        "# io.imshow(normalize_image(mask))\n",
        "# plt.show()  \n",
        "mask1 = polygon2mask(ihouse1_for_stitch.shape[:2], ihouse1_for_stitch_points[:, ::-1]).astype(np.uint8)\n",
        "mask2 = polygon2mask(ihouse2_for_stitch.shape[:2], ihouse2_for_stitch_points[:, ::-1]).astype(np.uint8)\n",
        "mask1_width = mask1.shape[1]\n",
        "gray_value = 0.8\n",
        "height = mask1.shape[0] \n",
        "width = mask1.shape[1]\n",
        "print(width)\n",
        "gray_mask_left = np.full((height, width*4//9), gray_value)\n",
        "black_mask_right = np.zeros((height, width*5//9), dtype=np.uint8)\n",
        "gray_mask_right = np.full((height, width*5//9), gray_value)\n",
        "black_mask_left = np.zeros((height, width*4//9), dtype=np.uint8)\n",
        "gray_right = np.concatenate((black_mask_left, gray_mask_right), axis=1)\n",
        "gray_left = np.concatenate((gray_mask_left, black_mask_right), axis=1)\n",
        "mask1_grayed = normalize_image(mask1)  \n",
        "mask1_grayed = np.where(mask1_grayed == 1.0, 0.4444444444444445, mask1_grayed)\n",
        "mask1_grayed = np.where(mask1_grayed == 0.0, 1.0, mask1_grayed)\n",
        "mask1_grayed = np.where(mask1_grayed == 0.4444444444444445, 0.0, mask1_grayed)\n",
        "mask2_grayed = normalize_image(mask2)   \n",
        "mask2_grayed = np.where(mask2_grayed == 1.0, 0.4444444444444445, mask2_grayed)\n",
        "mask2_grayed = np.where(mask2_grayed == 0.0, 1.0, mask2_grayed)\n",
        "mask2_grayed = np.where(mask2_grayed == 0.4444444444444445, 0.0, mask2_grayed) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 551,
      "metadata": {},
      "outputs": [],
      "source": [
        "room1 = io.imread('images/room1.png')\n",
        "room2 = io.imread('images/room2.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 552,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open (\"images/room1_room2.json\")\n",
        "json_data = json.load(f)\n",
        "room1_for_stitch_points = np.array(json_data['im1Points'])\n",
        "room2_for_stitch_points = np.array(json_data['im2Points'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 553,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lf/lddj8h6s3m3g8fkfp14cq4bw0000gn/T/ipykernel_71220/628019653.py:13: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  H_flatten = np.linalg.lstsq(A, B)[0]\n"
          ]
        }
      ],
      "source": [
        "roomH = computeH(room1_for_stitch_points, room2_for_stitch_points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 554,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done with color 0\n",
            "done with color 1\n",
            "done with color 2\n",
            "done with color 3\n"
          ]
        }
      ],
      "source": [
        "room1_warped = warp_image(room1, roomH, 'linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 555,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2da0d2b90>"
            ]
          },
          "execution_count": 555,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "io.imshow(normalize_image(room1_warped[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 532,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done with color 0\n",
            "done with color 1\n",
            "done with color 2\n",
            "done with color 3\n"
          ]
        }
      ],
      "source": [
        "room2_warped = warp_image(room2, roomH, 'linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 457,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(500, 699, 4)"
            ]
          },
          "execution_count": 457,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "room1_warped[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 533,
      "metadata": {},
      "outputs": [],
      "source": [
        "room1_warped_img = (room1_warped[0] * 255).astype(np.uint8)\n",
        "room2_warped_img = (room2_warped[0] * 255).astype(np.uint8) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 539,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2f1326990>"
            ]
          },
          "execution_count": 539,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "io.imshow(normalize_image(room2_warped[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 556,
      "metadata": {},
      "outputs": [],
      "source": [
        "room1_warped_img = normalize_image(room1_warped[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 606,
      "metadata": {},
      "outputs": [],
      "source": [
        "room1_aligned, room2_aligned = io.imread('room1_aligned.png'), io.imread('room2_aligned.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 560,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2f561a2d0>"
            ]
          },
          "execution_count": 560,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "io.imshow(room1_aligned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 607,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open (\"room1_aligned_room2_aligned (1).json\")\n",
        "json_data = json.load(f)\n",
        "room1_for_stitch_points = np.array(json_data['im1Points'])\n",
        "room2_for_stitch_points = np.array(json_data['im2Points'])\n",
        "mask1 = polygon2mask(room1_aligned.shape[:2], room1_for_stitch_points[:, ::-1]).astype(np.uint8)\n",
        "mask2 = polygon2mask(room2_aligned.shape[:2], room2_for_stitch_points[:, ::-1]).astype(np.uint8)\n",
        "mask1 = normalize_image(mask1)  \n",
        "mask2 = normalize_image(mask2)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 598,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  2,   0],\n",
              "       [167,   2],\n",
              "       [350,  40],\n",
              "       [340, 271],\n",
              "       [  1, 272]])"
            ]
          },
          "execution_count": 598,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "room1_for_stitch_points "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 486,
      "metadata": {},
      "outputs": [],
      "source": [
        "# io.imshow(mask1)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 608,
      "metadata": {},
      "outputs": [],
      "source": [
        "room1_for_stitch_resized = room1_aligned[:, :, :3]\n",
        "room2_for_stitch_resized = room2_aligned[:, :, :3]\n",
        "mask1_converted = cv2.convertScaleAbs(mask1, alpha=255)\n",
        "mask1_resized = cv2.cvtColor(mask1_converted, cv2.COLOR_GRAY2BGR)\n",
        "mask1_grayed_finalized = normalize_image(mask1_resized / 255.0) \n",
        "mask2_converted = cv2.convertScaleAbs(mask2, alpha=255)\n",
        "mask2_resized = cv2.cvtColor(mask2_converted, cv2.COLOR_GRAY2BGR)\n",
        "mask2_grayed_finalized = normalize_image(mask2_resized / 255.0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 609,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2f1342f90>"
            ]
          },
          "execution_count": 609,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "io.imshow(normalize_image(room2_for_stitch_resized))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 610,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2f1372450>"
            ]
          },
          "execution_count": 610,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "io.imshow(normalize_image(mask2_grayed_finalized))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 611,
      "metadata": {},
      "outputs": [],
      "source": [
        "room1_combined = combine_laplacian_stacks(room1_for_stitch_resized, room2_for_stitch_resized, 5, mask1_grayed_finalized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 612,
      "metadata": {},
      "outputs": [],
      "source": [
        "io.imshow(normalize_image(room1_combined))\n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 632,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cylindrical_mapping(image, focal_length):\n",
        "    height, width, _ = image.shape\n",
        "    cylindrical_image = np.zeros_like(image, dtype=np.uint8)\n",
        "    cy, cx = height / 2, width / 2\n",
        "    for y in range(height):\n",
        "        for x in range(width):\n",
        "            theta = (x - cx) / focal_length\n",
        "            h = (y - cy) / focal_length\n",
        "            src_x = int(focal_length * np.tan(theta) + cx)\n",
        "            src_y = int(focal_length * h + cy)\n",
        "            if 0 <= src_x < width and 0 <= src_y < height:\n",
        "                cylindrical_image[y, x] = image[src_y, src_x]\n",
        "\n",
        "    return cylindrical_image\n",
        "\n",
        "focal_length = 1000\n",
        "cylindrical_result = cylindrical_mapping(room1_combined, focal_length)\n",
        "cv2.imshow('Cylindrical Projection', normalize_image(cylindrical_result))\n",
        "plt.show()\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()\n",
        "# cv2.imwrite('cylindrical_projection.jpg', cylindrical_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 635,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "unhashable type: 'numpy.ndarray'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/xiaowenyuan/Desktop/proj4/Image_Warping_and_Mosaicing.ipynb Cell 75\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaowenyuan/Desktop/proj4/Image_Warping_and_Mosaicing.ipynb#Y312sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m v \u001b[39m=\u001b[39m (theta_sph \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39mpi) \u001b[39m*\u001b[39m (h \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaowenyuan/Desktop/proj4/Image_Warping_and_Mosaicing.ipynb#Y312sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m mapped_image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mremap(stitched_image, u\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32), v\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32), interpolation\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mINTER_LINEAR, borderMode\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mBORDER_CONSTANT)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xiaowenyuan/Desktop/proj4/Image_Warping_and_Mosaicing.ipynb#Y312sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m plt\u001b[39m.\u001b[39;49mimshow(\u001b[39m'\u001b[39;49m\u001b[39mMapped Image\u001b[39;49m\u001b[39m'\u001b[39;49m, normalize_image(mapped_image))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaowenyuan/Desktop/proj4/Image_Warping_and_Mosaicing.ipynb#Y312sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# cv2.waitKey(0)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaowenyuan/Desktop/proj4/Image_Warping_and_Mosaicing.ipynb#Y312sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# cv2.destroyAllWindows()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaowenyuan/Desktop/proj4/Image_Warping_and_Mosaicing.ipynb#Y312sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaowenyuan/Desktop/proj4/Image_Warping_and_Mosaicing.ipynb#Y312sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# # Save the mapped image if needed\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaowenyuan/Desktop/proj4/Image_Warping_and_Mosaicing.ipynb#Y312sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# cv2.imwrite('mapped_sphere.jpg', mapped_image)\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/pyplot.py:3346\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   3325\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mimshow)\n\u001b[1;32m   3326\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimshow\u001b[39m(\n\u001b[1;32m   3327\u001b[0m     X: ArrayLike \u001b[39m|\u001b[39m PIL\u001b[39m.\u001b[39mImage\u001b[39m.\u001b[39mImage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3344\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   3345\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AxesImage:\n\u001b[0;32m-> 3346\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39;49mimshow(\n\u001b[1;32m   3347\u001b[0m         X,\n\u001b[1;32m   3348\u001b[0m         cmap\u001b[39m=\u001b[39;49mcmap,\n\u001b[1;32m   3349\u001b[0m         norm\u001b[39m=\u001b[39;49mnorm,\n\u001b[1;32m   3350\u001b[0m         aspect\u001b[39m=\u001b[39;49maspect,\n\u001b[1;32m   3351\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[1;32m   3352\u001b[0m         alpha\u001b[39m=\u001b[39;49malpha,\n\u001b[1;32m   3353\u001b[0m         vmin\u001b[39m=\u001b[39;49mvmin,\n\u001b[1;32m   3354\u001b[0m         vmax\u001b[39m=\u001b[39;49mvmax,\n\u001b[1;32m   3355\u001b[0m         origin\u001b[39m=\u001b[39;49morigin,\n\u001b[1;32m   3356\u001b[0m         extent\u001b[39m=\u001b[39;49mextent,\n\u001b[1;32m   3357\u001b[0m         interpolation_stage\u001b[39m=\u001b[39;49minterpolation_stage,\n\u001b[1;32m   3358\u001b[0m         filternorm\u001b[39m=\u001b[39;49mfilternorm,\n\u001b[1;32m   3359\u001b[0m         filterrad\u001b[39m=\u001b[39;49mfilterrad,\n\u001b[1;32m   3360\u001b[0m         resample\u001b[39m=\u001b[39;49mresample,\n\u001b[1;32m   3361\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m   3362\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}),\n\u001b[1;32m   3363\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   3364\u001b[0m     )\n\u001b[1;32m   3365\u001b[0m     sci(__ret)\n\u001b[1;32m   3366\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1467\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/axes/_axes.py:5737\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5532\u001b[0m \u001b[39m@_preprocess_data\u001b[39m()\n\u001b[1;32m   5533\u001b[0m \u001b[39m@_docstring\u001b[39m\u001b[39m.\u001b[39minterpd\n\u001b[1;32m   5534\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimshow\u001b[39m(\u001b[39mself\u001b[39m, X, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, aspect\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5537\u001b[0m            interpolation_stage\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, filternorm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, filterrad\u001b[39m=\u001b[39m\u001b[39m4.0\u001b[39m,\n\u001b[1;32m   5538\u001b[0m            resample\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, url\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   5539\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5540\u001b[0m \u001b[39m    Display data as an image, i.e., on a 2D regular raster.\u001b[39;00m\n\u001b[1;32m   5541\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5735\u001b[0m \u001b[39m    (unassociated) alpha representation.\u001b[39;00m\n\u001b[1;32m   5736\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5737\u001b[0m     im \u001b[39m=\u001b[39m mimage\u001b[39m.\u001b[39;49mAxesImage(\u001b[39mself\u001b[39;49m, cmap\u001b[39m=\u001b[39;49mcmap, norm\u001b[39m=\u001b[39;49mnorm,\n\u001b[1;32m   5738\u001b[0m                           interpolation\u001b[39m=\u001b[39;49minterpolation, origin\u001b[39m=\u001b[39;49morigin,\n\u001b[1;32m   5739\u001b[0m                           extent\u001b[39m=\u001b[39;49mextent, filternorm\u001b[39m=\u001b[39;49mfilternorm,\n\u001b[1;32m   5740\u001b[0m                           filterrad\u001b[39m=\u001b[39;49mfilterrad, resample\u001b[39m=\u001b[39;49mresample,\n\u001b[1;32m   5741\u001b[0m                           interpolation_stage\u001b[39m=\u001b[39;49minterpolation_stage,\n\u001b[1;32m   5742\u001b[0m                           \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   5744\u001b[0m     \u001b[39mif\u001b[39;00m aspect \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[1;32m   5745\u001b[0m             im\u001b[39m.\u001b[39mis_transform_set()\n\u001b[1;32m   5746\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m im\u001b[39m.\u001b[39mget_transform()\u001b[39m.\u001b[39mcontains_branch(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransData)):\n\u001b[1;32m   5747\u001b[0m         aspect \u001b[39m=\u001b[39m mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39mimage.aspect\u001b[39m\u001b[39m'\u001b[39m]\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/image.py:912\u001b[0m, in \u001b[0;36mAxesImage.__init__\u001b[0;34m(self, ax, cmap, norm, interpolation, origin, extent, filternorm, filterrad, resample, interpolation_stage, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, ax,\n\u001b[1;32m    897\u001b[0m              \u001b[39m*\u001b[39m,\n\u001b[1;32m    898\u001b[0m              cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    907\u001b[0m              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    908\u001b[0m              ):\n\u001b[1;32m    910\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extent \u001b[39m=\u001b[39m extent\n\u001b[0;32m--> 912\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    913\u001b[0m         ax,\n\u001b[1;32m    914\u001b[0m         cmap\u001b[39m=\u001b[39;49mcmap,\n\u001b[1;32m    915\u001b[0m         norm\u001b[39m=\u001b[39;49mnorm,\n\u001b[1;32m    916\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[1;32m    917\u001b[0m         origin\u001b[39m=\u001b[39;49morigin,\n\u001b[1;32m    918\u001b[0m         filternorm\u001b[39m=\u001b[39;49mfilternorm,\n\u001b[1;32m    919\u001b[0m         filterrad\u001b[39m=\u001b[39;49mfilterrad,\n\u001b[1;32m    920\u001b[0m         resample\u001b[39m=\u001b[39;49mresample,\n\u001b[1;32m    921\u001b[0m         interpolation_stage\u001b[39m=\u001b[39;49minterpolation_stage,\n\u001b[1;32m    922\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    923\u001b[0m     )\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/image.py:261\u001b[0m, in \u001b[0;36m_ImageBase.__init__\u001b[0;34m(self, ax, cmap, norm, interpolation, origin, filternorm, filterrad, resample, interpolation_stage, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, ax,\n\u001b[1;32m    249\u001b[0m              cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    250\u001b[0m              norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    259\u001b[0m              ):\n\u001b[1;32m    260\u001b[0m     martist\u001b[39m.\u001b[39mArtist\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 261\u001b[0m     cm\u001b[39m.\u001b[39;49mScalarMappable\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, norm, cmap)\n\u001b[1;32m    262\u001b[0m     \u001b[39mif\u001b[39;00m origin \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m         origin \u001b[39m=\u001b[39m mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39mimage.origin\u001b[39m\u001b[39m'\u001b[39m]\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/cm.py:411\u001b[0m, in \u001b[0;36mScalarMappable.__init__\u001b[0;34m(self, norm, cmap)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_norm(norm)  \u001b[39m# The Normalize instance of this ScalarMappable.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcmap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# So that the setter knows we're initializing.\u001b[39;00m\n\u001b[0;32m--> 411\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_cmap(cmap)  \u001b[39m# The Colormap instance of this ScalarMappable.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[39m#: The last colorbar associated with this ScalarMappable. May be None.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolorbar \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/cm.py:600\u001b[0m, in \u001b[0;36mScalarMappable.set_cmap\u001b[0;34m(self, cmap)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[39mSet the colormap for luminance data.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39mcmap : `.Colormap` or str or None\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    598\u001b[0m in_init \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcmap \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 600\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcmap \u001b[39m=\u001b[39m _ensure_cmap(cmap)\n\u001b[1;32m    601\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m in_init:\n\u001b[1;32m    602\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchanged()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/cm.py:738\u001b[0m, in \u001b[0;36m_ensure_cmap\u001b[0;34m(cmap)\u001b[0m\n\u001b[1;32m    735\u001b[0m cmap_name \u001b[39m=\u001b[39m cmap \u001b[39mif\u001b[39;00m cmap \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m\"\u001b[39m\u001b[39mimage.cmap\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    736\u001b[0m \u001b[39m# use check_in_list to ensure type stability of the exception raised by\u001b[39;00m\n\u001b[1;32m    737\u001b[0m \u001b[39m# the internal usage of this (ValueError vs KeyError)\u001b[39;00m\n\u001b[0;32m--> 738\u001b[0m \u001b[39mif\u001b[39;00m cmap_name \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m _colormaps:\n\u001b[1;32m    739\u001b[0m     _api\u001b[39m.\u001b[39mcheck_in_list(\u001b[39msorted\u001b[39m(_colormaps), cmap\u001b[39m=\u001b[39mcmap_name)\n\u001b[1;32m    740\u001b[0m \u001b[39mreturn\u001b[39;00m mpl\u001b[39m.\u001b[39mcolormaps[cmap_name]\n",
            "File \u001b[0;32m<frozen _collections_abc>:780\u001b[0m, in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/matplotlib/cm.py:86\u001b[0m, in \u001b[0;36mColormapRegistry.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, item):\n\u001b[1;32m     85\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmaps[item]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     87\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mitem\u001b[39m!r}\u001b[39;00m\u001b[39m is not a known colormap name\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "stitched_image = room1_combined\n",
        "radius = 1.0\n",
        "phi, theta = np.mgrid[0.0:2.0*np.pi:100j, 0.0:np.pi:50j]\n",
        "x = radius * np.sin(theta) * np.cos(phi)\n",
        "y = radius * np.sin(theta) * np.sin(phi)\n",
        "z = radius * np.cos(theta)\n",
        "theta_sph = np.arctan2(np.sqrt(x**2 + y**2), z)\n",
        "phi_sph = np.arctan2(y, x)\n",
        "h, w, _ = stitched_image.shape\n",
        "u = ((phi_sph + np.pi) / (2 * np.pi)) * (w - 1)\n",
        "v = (theta_sph / np.pi) * (h - 1)\n",
        "mapped_image = cv2.remap(stitched_image, u.astype(np.float32), v.astype(np.float32), interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
        "\n",
        "plt.imshow('Mapped Image', normalize_image(mapped_image))\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()\n",
        "# # Save the mapped image if needed\n",
        "# cv2.imwrite('mapped_sphere.jpg', mapped_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 636,
      "metadata": {},
      "outputs": [],
      "source": [
        "image1 = room1 \n",
        "image2 = room2\n",
        "sift = cv2.SIFT_create()\n",
        "keypoints1, descriptors1 = sift.detectAndCompute(image1, None)\n",
        "keypoints2, descriptors2 = sift.detectAndCompute(image2, None)\n",
        "\n",
        "bf = cv2.BFMatcher()\n",
        "matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
        "\n",
        "good_matches = []\n",
        "for m, n in matches:\n",
        "    if m.distance < 0.75 * n.distance:\n",
        "        good_matches.append(m)\n",
        "\n",
        "if len(good_matches) >= 4:\n",
        "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "\n",
        "    H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "\n",
        "    # Image warping\n",
        "    warped_image = cv2.warpPerspective(image1, H, (image1.shape[1] + image2.shape[1], image1.shape[0]))\n",
        "\n",
        "    # Combine the two images\n",
        "    result = np.copy(warped_image)\n",
        "    result[0:image2.shape[0], 0:image2.shape[1]] = image2\n",
        "\n",
        "    # Display or save the result\n",
        "    cv2.imshow('Spherical Stitching', result)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    # Save the result if needed\n",
        "    cv2.imwrite('spherical_stitching_result.jpg', result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
