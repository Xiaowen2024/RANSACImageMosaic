{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CG-ydemPue0V"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial import Delaunay\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.draw import polygon, polygon2mask\n",
        "from scipy.interpolate import griddata\n",
        "import skimage.io as io\n",
        "import skimage as sk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "stadium1 = io.imread('images/stadium_resized_1.png')\n",
        "stadium2 = io.imread('images/stadium_resized_2.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open(\"stadidum_resized_1_stadium_resized_2.json\")\n",
        "json_data = json.load(f)\n",
        "im1_points = np.array(json_data['im1Points'])\n",
        "im2_points = np.array(json_data['im2Points']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P9BnY2lIuwSZ"
      },
      "outputs": [],
      "source": [
        "def computeH(im1_points, im2_points):\n",
        "  A = []\n",
        "  B = []\n",
        "  for i in range(len(im1_points)):\n",
        "    p1 = im1_points[i]\n",
        "    p2 = im2_points[i] \n",
        "    A.append([p1[0], p1[1], 1, 0, 0, 0, -p1[0] * p2[0], -p1[1] * p2[0]])\n",
        "    A.append([0, 0, 0, p1[0], p1[1], 1, -p1[0] * p2[1], -p1[1] * p2[1]])\n",
        "    B.append(p2[0])\n",
        "    B.append(p2[1])\n",
        "  A = np.asarray(A)\n",
        "  B = np.asarray(B)\n",
        "  H_flatten = np.linalg.lstsq(A, B)[0]\n",
        "  H_flatten = np.asarray(H_flatten.tolist() + [1])\n",
        "  return np.reshape(H_flatten, (3, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UXITZ7kmwxCF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lf/lddj8h6s3m3g8fkfp14cq4bw0000gn/T/ipykernel_71220/628019653.py:13: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  H_flatten = np.linalg.lstsq(A, B)[0]\n"
          ]
        }
      ],
      "source": [
        "H = computeH(im1_points, im2_points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize(im):\n",
        "    return (im - np.amin(im)) / (np.amax(im) - np.amin(im))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def createGrid(xmin, xmax,ymin,ymax):\n",
        "    x_matrix = np.repeat(np.arange(xmin, xmax), (ymax - ymin)).reshape(-1, (ymax - ymin)).T\n",
        "    y_matrix = np.repeat(np.arange(ymin, ymax), (xmax - xmin)).reshape((ymax - ymin), (xmax - xmin))\n",
        "    return x_matrix, y_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def warpImage(im,H):\n",
        "    corners = [np.array([0,0, 1]),np.array([0,im.shape[0]-1, 1]),np.array([im.shape[1]-1,0, 1]),np.array([im.shape[1]-1,im.shape[0]-1, 1])]\n",
        "    warped_corners = [ corner @ H.T for corner in corners] \n",
        "    min_x, min_y = np.min(warped_corners, axis=0)[:2]\n",
        "    min_x_index, min_y_index = 0, 0 \n",
        "    min_x_sofar, min_y_sofar = warped_corners[0][0], warped_corners[0][1]\n",
        "    max_x_index, max_y_index = 0, 0\n",
        "    max_x_sofar, max_y_sofar = warped_corners[0][0], warped_corners[0][1]\n",
        "    for i in range(len(warped_corners)):\n",
        "        if warped_corners[i][0] < min_x_sofar:\n",
        "            min_x_index = i\n",
        "            min_x_sofar = warped_corners[i][0]\n",
        "        if warped_corners[i][0] > max_x_sofar:\n",
        "            max_x_index = i\n",
        "            max_x_sofar = warped_corners[i][0]\n",
        "        if warped_corners[i][1] < min_y_sofar:\n",
        "            min_y_index = i\n",
        "            min_y_sofar = warped_corners[i][1]\n",
        "        if warped_corners[i][1] > max_y_sofar:\n",
        "            max_y_index = i\n",
        "            max_y_sofar = warped_corners[i][1]\n",
        "    min_x, min_y = np.floor(min_x / warped_corners[min_x_index][2]), np.floor(min_y / warped_corners[min_y_index][2])\n",
        "    max_x, max_y = np.max(warped_corners, axis=0)[:2]\n",
        "    max_x, max_y = np.ceil(max_x / warped_corners[max_x_index][2]), np.ceil(max_y / warped_corners[max_y_index][2])\n",
        "    warped_corners = np.asanyarray(warped_corners)\n",
        "    new_width = int(abs(min_x - max_x))\n",
        "    new_height = int(abs(min_y - max_y)) \n",
        "    x_coords, y_coords = createGrid(int(min_x), int(max_x), int(min_y), int(max_y))\n",
        "    coords = np.stack((x_coords, y_coords, np.ones(x_coords.shape)), axis = 2)\n",
        "    coords = coords.reshape((x_coords.size, 3))\n",
        "    inv_warp_x, inv_warp_y, _ = coords.T\n",
        "    img_gridx,img_gridy = createGrid(0, im.shape[1], 0, im.shape[0])\n",
        "    img_coords = np.stack((img_gridx, img_gridy, np.ones(img_gridx.shape)), axis = 2)\n",
        "    img_coords = img_coords.reshape((img_gridx.size, 3))\n",
        "    img_x, img_y, _ = img_coords.T \n",
        "    interpret_values = [] \n",
        "    for i in range(im.shape[2]):\n",
        "        temp = griddata((img_x, img_y), im[:, :, i].flatten(), (inv_warp_x, inv_warp_y), method='linear', fill_value=0)\n",
        "        interpret_values.append(temp.reshape([new_height, new_width])) \n",
        "    return np.stack(interpret_values, axis = 2) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_image(im):\n",
        "    return (im - np.amin(im)) / (np.amax(im) - np.amin(im))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image Rectification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "rectify_im1 = io.imread('images/rectify_im1.png')\n",
        "rectify_im2 = io.imread('images/rectify_im2.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "rectify_im3 = io.imread('images/rectify_im3.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open(\"rectify_im1_rectify_im1.json\")\n",
        "json_data = json.load(f) \n",
        "rectify_im1_points = np.array(json_data['im1Points'])\n",
        "width = abs(np.min(rectify_im1_points, axis=0)[0] - np.max(rectify_im1_points, axis=0)[0])\n",
        "height = abs(np.min(rectify_im1_points, axis=0)[1] - np.max(rectify_im1_points, axis=0)[1])\n",
        "starting_point = np.min(rectify_im1_points, axis=0)[:2]\n",
        "im1_rectified_points = np.asarray([starting_point, [starting_point[0] + width, starting_point[1]], [starting_point[0] + width, starting_point[1] + height], [starting_point[0], starting_point[1] + height]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open(\"rectify_im3_rectify_im3.json\")\n",
        "json_data = json.load(f) \n",
        "rectify_im3_points = np.array(json_data['im1Points'])\n",
        "width = abs(np.min(rectify_im3_points, axis=0)[0] - np.max(rectify_im3_points, axis=0)[0])\n",
        "height = abs(np.min(rectify_im3_points, axis=0)[1] - np.max(rectify_im3_points, axis=0)[1])\n",
        "starting_point = np.min(rectify_im3_points, axis=0)[:2]\n",
        "im3_rectified_points = np.asarray([starting_point, [starting_point[0] + width, starting_point[1]], [starting_point[0] + width, starting_point[1] + height], [starting_point[0], starting_point[1] + height]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Blend the images into a mosaic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open(\"ihouse1_ihouse2.json\")\n",
        "json_data = json.load(f)\n",
        "ihouse1 = io.imread('images/ihouse1.png')\n",
        "ihouse2 = io.imread('images/ihouse2.png')\n",
        "ihouse1_points = np.array(json_data['im1Points'])\n",
        "ihouse2_points = np.array(json_data['im2Points']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lf/lddj8h6s3m3g8fkfp14cq4bw0000gn/T/ipykernel_71220/628019653.py:13: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  H_flatten = np.linalg.lstsq(A, B)[0]\n"
          ]
        }
      ],
      "source": [
        "ihouseH = computeH(ihouse1_points, ihouse2_points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "ihousewarped = warp_image(ihouse1,ihouseH, \"linear\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lf/lddj8h6s3m3g8fkfp14cq4bw0000gn/T/ipykernel_71220/1012367921.py:2: RuntimeWarning: invalid value encountered in divide\n",
            "  return (im - np.amin(im)) / (np.amax(im) - np.amin(im))\n"
          ]
        }
      ],
      "source": [
        "ihousewarped = normalize_image(ihousewarped[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.transform as sktr\n",
        "\n",
        "def get_points(im1, im2):\n",
        "    print('Please select 2 points in each image for alignment.')\n",
        "    plt.imshow(im1)\n",
        "    p1, p2 = plt.ginput(2)\n",
        "    plt.close()\n",
        "    plt.imshow(im2)\n",
        "    p3, p4 = plt.ginput(2)\n",
        "    plt.close()\n",
        "    return (p1, p2, p3, p4)\n",
        "\n",
        "def recenter(im, r, c):\n",
        "    R, C, _ = im.shape\n",
        "    rpad = (int) (np.abs(2*r+1 - R))\n",
        "    cpad = (int) (np.abs(2*c+1 - C))\n",
        "    return np.pad(\n",
        "        im, [(0 if r > (R-1)/2 else rpad, 0 if r < (R-1)/2 else rpad),\n",
        "             (0 if c > (C-1)/2 else cpad, 0 if c < (C-1)/2 else cpad),\n",
        "             (0, 0)], 'constant')\n",
        "\n",
        "def find_centers(p1, p2):\n",
        "    cx = np.round(np.mean([p1[0], p2[0]]))\n",
        "    cy = np.round(np.mean([p1[1], p2[1]]))\n",
        "    return cx, cy\n",
        "\n",
        "def align_image_centers(im1, im2, pts):\n",
        "    p1, p2, p3, p4 = pts\n",
        "    h1, w1, b1 = im1.shape\n",
        "    h2, w2, b2 = im2.shape\n",
        "\n",
        "    cx1, cy1 = find_centers(p1, p2)\n",
        "    cx2, cy2 = find_centers(p3, p4)\n",
        "\n",
        "    im1 = recenter(im1, cy1, cx1)\n",
        "    im2 = recenter(im2, cy2, cx2)\n",
        "    return im1, im2\n",
        "\n",
        "def rescale_images(im1, im2, pts):\n",
        "    p1, p2, p3, p4 = pts\n",
        "    len1 = np.sqrt((p2[1] - p1[1])**2 + (p2[0] - p1[0])**2)\n",
        "    len2 = np.sqrt((p4[1] - p3[1])**2 + (p4[0] - p3[0])**2)\n",
        "    dscale = len2/len1\n",
        "    if dscale < 1:\n",
        "        im1 = sktr.rescale(im1, (dscale, dscale, 1))\n",
        "    else:\n",
        "        im2 = sktr.rescale(im2, (1./dscale, 1./dscale, 1))\n",
        "    return im1, im2\n",
        "\n",
        "def rotate_im1(im1, im2, pts):\n",
        "    p1, p2, p3, p4 = pts\n",
        "    theta1 = math.atan2(-(p2[1] - p1[1]), (p2[0] - p1[0]))\n",
        "    theta2 = math.atan2(-(p4[1] - p3[1]), (p4[0] - p3[0]))\n",
        "    dtheta = theta2 - theta1\n",
        "    im1 = sktr.rotate(im1, dtheta*180/np.pi)\n",
        "    return im1, dtheta\n",
        "\n",
        "def match_img_size(im1, im2):\n",
        "    # Make images the same size\n",
        "    h1, w1, c1 = im1.shape\n",
        "    h2, w2, c2 = im2.shape\n",
        "    if h1 < h2:\n",
        "        im2 = im2[int(np.floor((h2-h1)/2.)) : -int(np.ceil((h2-h1)/2.)), :, :]\n",
        "    elif h1 > h2:\n",
        "        im1 = im1[int(np.floor((h1-h2)/2.)) : -int(np.ceil((h1-h2)/2.)), :, :]\n",
        "    if w1 < w2:\n",
        "        im2 = im2[:, int(np.floor((w2-w1)/2.)) : -int(np.ceil((w2-w1)/2.)), :]\n",
        "    elif w1 > w2:\n",
        "        im1 = im1[:, int(np.floor((w1-w2)/2.)) : -int(np.ceil((w1-w2)/2.)), :]\n",
        "    assert im1.shape == im2.shape\n",
        "    return im1, im2\n",
        "\n",
        "def align_images(im1, im2):\n",
        "    pts = get_points(im1, im2)\n",
        "    im1, im2 = align_image_centers(im1, im2, pts)\n",
        "    im1, im2 = rescale_images(im1, im2, pts)\n",
        "    im1, angle = rotate_im1(im1, im2, pts)\n",
        "    im1, im2 = match_img_size(im1, im2)\n",
        "    return im1, im2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "import PyQt5\n",
        "%matplotlib qt5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select 2 points in each image for alignment.\n"
          ]
        }
      ],
      "source": [
        "aligned_ihouse1, aligned_ihouse2 = align_images(ihousewarped, ihouse2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done with color 0\n",
            "done with color 1\n",
            "done with color 2\n",
            "done with color 3\n"
          ]
        }
      ],
      "source": [
        "rectify_im1_warped = warp_image(rectify_im1, rectify_im1_H, 'linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.signal import convolve2d\n",
        "def create_gaussian_stacks(im, N):\n",
        "    image_pyramids = [] \n",
        "    temp = np.array([im[:,:,0], im[:,:,1], im[:,:,2]])\n",
        "    image_pyramids.append(im)\n",
        "    size, sigma = 6, 1\n",
        "    while N > 0:\n",
        "        GaussianFilter = np.outer(cv2.getGaussianKernel(size, sigma), cv2.getGaussianKernel(size, sigma))\n",
        "        im_blurred_r = convolve2d(temp[0], GaussianFilter, \"same\")\n",
        "        im_blurred_g = convolve2d(temp[1], GaussianFilter, \"same\")\n",
        "        im_blurred_b = convolve2d(temp[2], GaussianFilter, \"same\")\n",
        "        im_blurred = np.stack((im_blurred_r, im_blurred_g, im_blurred_b), axis=2)\n",
        "        image_pyramids.append(im_blurred)\n",
        "        temp = [im_blurred_r, im_blurred_g, im_blurred_b]\n",
        "        size, sigma = size * 2, sigma * 2\n",
        "        N -= 1 \n",
        "    return np.array(image_pyramids)\n",
        "\n",
        "def create_laplacian_stacks(im, N):\n",
        "    gaussian_pyramids = create_gaussian_stacks(im, N)\n",
        "    laplacian_pyramids = []\n",
        "    for i in range(1, len(gaussian_pyramids)-1):\n",
        "        laplacian_pyramids.append(gaussian_pyramids[i] - gaussian_pyramids[i-1])\n",
        "    laplacian_pyramids.append(gaussian_pyramids[-1])\n",
        "    return np.array(laplacian_pyramids) \n",
        "\n",
        "def create_gaussian_masks(mask, N, sigma):\n",
        "    temp = [mask[:, :, 0], mask[:, :, 1], mask[:, :, 2]]\n",
        "    mask_stacks = [mask]\n",
        "    while N > 1:\n",
        "        size = sigma * 6\n",
        "        GaussianFilter = np.outer(cv2.getGaussianKernel(size, sigma), cv2.getGaussianKernel(size, sigma))\n",
        "        mask_r = convolve2d(temp[0], GaussianFilter, \"same\")\n",
        "        mask_g = convolve2d(temp[1], GaussianFilter, \"same\")\n",
        "        mask_b = convolve2d(temp[2], GaussianFilter, \"same\")\n",
        "        mask_stacked = np.stack((mask_r, mask_g, mask_b), axis=2)\n",
        "        mask_stacks.append(mask_stacked)\n",
        "        temp = [mask_r, mask_g, mask_b]\n",
        "        sigma *= 2\n",
        "        N -= 1 \n",
        "    return np.array(mask_stacks) \n",
        "\n",
        "def combine_laplacian_stacks(im1, im2, N, binary_mask_right):\n",
        "    laplacian_stack1 = create_laplacian_stacks(im1, N)\n",
        "    laplacian_stack2 = create_laplacian_stacks(im2, N)\n",
        "    mask_stack = create_gaussian_masks(binary_mask_right, N, 1)\n",
        "    combined_stack = []\n",
        "    for i in range(len(laplacian_stack1)):\n",
        "        left = laplacian_stack1[i] * mask_stack[i]\n",
        "        right = (np.ones(mask_stack[i].shape) - mask_stack[i]) * laplacian_stack2[i]\n",
        "        combined_stack.append(left + right)\n",
        "    return np.sum(combined_stack, axis = 0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select 2 points in each image for alignment.\n"
          ]
        }
      ],
      "source": [
        "ihouse1_aligned, ihouse2_aligned = align_images(ihouse1_warped, ihouse2_warped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please select 2 points in each image for alignment.\n"
          ]
        }
      ],
      "source": [
        "ihouse1_for_stitch = io.imread('images/ihouse1_aligned.png')\n",
        "ihouse2_for_stitch = io.imread('images/ihouse2_aligned.png')\n",
        "ihouse1_for_stitch, ihouse2_for_stitch = align_images(ihouse1_for_stitch, ihouse2_for_stitch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_gaussian_stacks(im, N, sigma):\n",
        "    image_pyramids = [] \n",
        "    temp = np.array([im[:,:,0], im[:,:,1], im[:,:,2]])\n",
        "    image_pyramids.append(im) \n",
        "    size = sigma * 6\n",
        "    while N > 0:\n",
        "        GaussianFilter = np.outer(cv2.getGaussianKernel(size, sigma), cv2.getGaussianKernel(size, sigma))\n",
        "        im_blurred_r = convolve2d(temp[0], GaussianFilter, \"same\", boundary=\"symm\")\n",
        "        im_blurred_g = convolve2d(temp[1], GaussianFilter, \"same\", boundary=\"symm\")\n",
        "        im_blurred_b = convolve2d(temp[2], GaussianFilter, \"same\", boundary=\"symm\")\n",
        "        im_blurred = np.stack((im_blurred_r, im_blurred_g, im_blurred_b), axis=2)\n",
        "        image_pyramids.append(im_blurred)\n",
        "        temp = [im_blurred_r, im_blurred_g, im_blurred_b]\n",
        "        size, sigma = size * 2, sigma * 2 \n",
        "        N -= 1 \n",
        "    return np.array(image_pyramids)\n",
        "\n",
        "def create_laplacian_stacks(im, N):\n",
        "    gaussian_pyramids = create_gaussian_stacks(im, N, 1)\n",
        "    laplacian_pyramids = []\n",
        "    for i in range(len(gaussian_pyramids)-2):\n",
        "        laplacian_pyramids.append(gaussian_pyramids[i] - gaussian_pyramids[i+1])\n",
        "    laplacian_pyramids.append(gaussian_pyramids[-1])\n",
        "    return np.array(laplacian_pyramids) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {},
      "outputs": [],
      "source": [
        "def combine_laplacian_stacks(im1, im2, N, binary_mask_right):\n",
        "    laplacian_stack1 = create_laplacian_stacks(im1, N)\n",
        "    laplacian_stack2 = create_laplacian_stacks(im2, N)\n",
        "    mask_stack = create_gaussian_masks(binary_mask_right, N, 5)\n",
        "    combined_stack = []\n",
        "    for i in range(len(laplacian_stack1)):\n",
        "        left = laplacian_stack1[i] * mask_stack[i]\n",
        "        right = (np.ones(mask_stack[i].shape) - mask_stack[i]) * laplacian_stack2[i]\n",
        "        combined_stack.append(left + right)\n",
        "    return np.sum(combined_stack, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 374,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "738\n"
          ]
        }
      ],
      "source": [
        "f = open (\"ihouse1_aligned_ihouse2_aligned.json\")\n",
        "json_data = json.load(f)\n",
        "ihouse1_for_stitch_points = np.array(json_data['im1Points'])\n",
        "ihouse2_for_stitch_points = np.array(json_data['im2Points'])\n",
        "# mask = np.array(polygon(ihouse1_for_stitch_points[:, 0], ihouse1_for_stitch_points[:, 1])).T\n",
        "# io.imshow(normalize_image(mask))\n",
        "# plt.show()  \n",
        "mask1 = polygon2mask(ihouse1_for_stitch.shape[:2], ihouse1_for_stitch_points[:, ::-1]).astype(np.uint8)\n",
        "mask2 = polygon2mask(ihouse2_for_stitch.shape[:2], ihouse2_for_stitch_points[:, ::-1]).astype(np.uint8)\n",
        "mask1_width = mask1.shape[1]\n",
        "gray_value = 0.8\n",
        "height = mask1.shape[0] \n",
        "width = mask1.shape[1]\n",
        "print(width)\n",
        "gray_mask_left = np.full((height, width*4//9), gray_value)\n",
        "black_mask_right = np.zeros((height, width*5//9), dtype=np.uint8)\n",
        "gray_mask_right = np.full((height, width*5//9), gray_value)\n",
        "black_mask_left = np.zeros((height, width*4//9), dtype=np.uint8)\n",
        "gray_right = np.concatenate((black_mask_left, gray_mask_right), axis=1)\n",
        "gray_left = np.concatenate((gray_mask_left, black_mask_right), axis=1)\n",
        "mask1_grayed = normalize_image(mask1)  \n",
        "mask1_grayed = np.where(mask1_grayed == 1.0, 0.4444444444444445, mask1_grayed)\n",
        "mask1_grayed = np.where(mask1_grayed == 0.0, 1.0, mask1_grayed)\n",
        "mask1_grayed = np.where(mask1_grayed == 0.4444444444444445, 0.0, mask1_grayed)\n",
        "mask2_grayed = normalize_image(mask2)   \n",
        "mask2_grayed = np.where(mask2_grayed == 1.0, 0.4444444444444445, mask2_grayed)\n",
        "mask2_grayed = np.where(mask2_grayed == 0.0, 1.0, mask2_grayed)\n",
        "mask2_grayed = np.where(mask2_grayed == 0.4444444444444445, 0.0, mask2_grayed) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 375,
      "metadata": {},
      "outputs": [],
      "source": [
        "ihouse1_for_stitch_resized = ihouse1_for_stitch[:, :, :3]\n",
        "ihouse2_for_stitch_resized = ihouse2_for_stitch[:, :, :3]\n",
        "mask1_grayed_converted = cv2.convertScaleAbs(mask1_grayed, alpha=255)\n",
        "mask1_grayed_resized = cv2.cvtColor(mask1_grayed_converted, cv2.COLOR_GRAY2BGR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 376,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask2_grayed_converted = cv2.convertScaleAbs(mask2_grayed, alpha=255)\n",
        "mask2_grayed_resized = cv2.cvtColor(mask2_grayed_converted, cv2.COLOR_GRAY2BGR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 391,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(396, 738, 3)"
            ]
          },
          "execution_count": 391,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mask1_grayed_finalized = mask1_grayed_resized /  255.0\n",
        "mask1_grayed_finalized = 1 - mask1_grayed_finalized\n",
        "mask1_grayed_finalized .shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask2_grayed_finalized = mask2_grayed_resized / 255.0\n",
        "mask2_grayed_finalized = 1 - mask2_grayed_finalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 425,
      "metadata": {},
      "outputs": [],
      "source": [
        "overlap = cv2.bitwise_and(mask1_grayed_finalized, mask2_grayed_finalized)\n",
        "overlap_grayed = np.where(overlap == 1, 0.4, overlap)\n",
        "overlap_blurred = cv2.GaussianBlur(overlap_grayed, (5, 5), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 440,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 440,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mask_with_overlap = normalize_image(mask1_grayed_finalized - overlap_grayed)\n",
        "mask_with_overlap_blurred = cv2.GaussianBlur(mask_with_overlap, (5, 5), 0)\n",
        "mask_with_overlap_blurred.shape == mask1_grayed_finalized.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 437,
      "metadata": {},
      "outputs": [],
      "source": [
        "io.imshow(mask_with_overlap_blurred)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 370,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_combined = normalize_image(mask2_grayed_finalized + mask1_grayed_finalized)\n",
        "# mask_combined = np.where(mask_combined != 0.7784313725490196, 0.0, mask_combined)\n",
        "# # mask_combined = np.where(mask_combined == 0.6784313725490196, 0.9, mask_combined)\n",
        "# # mask_combined = np.where(mask_combined != 0.9, 0.0, mask_combined)\n",
        "io.imshow(normalize_image(mask_combined))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {},
      "outputs": [],
      "source": [
        "io.imshow(normalize_image(mask2_grayed_finalized))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 379,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_combined_blurred = cv2.GaussianBlur(mask_combined, (5, 5), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 380,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_combined_finalized = normalize_image(mask_combined_blurred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 404,
      "metadata": {},
      "outputs": [],
      "source": [
        "io.imshow(normalize_image(mask_combined_finalized))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 400,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 400,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mask_combined_finalized.shape == mask1_grayed_finalized.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 405,
      "metadata": {},
      "outputs": [],
      "source": [
        "io.imshow(normalize_image(mask1_grayed_finalized))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 441,
      "metadata": {},
      "outputs": [],
      "source": [
        "ihouse_combined = combine_laplacian_stacks(ihouse1_for_stitch_resized, ihouse2_for_stitch_resized, 5, mask_with_overlap_blurred)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 442,
      "metadata": {},
      "outputs": [],
      "source": [
        "io.imshow(normalize_image(ihouse_combined))\n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open (\"images/room1_room2.json\")\n",
        "json_data = json.load(f)\n",
        "ihouse1_for_stitch_points = np.array(json_data['im1Points'])\n",
        "ihouse2_for_stitch_points = np.array(json_data['im2Points'])\n",
        "# mask = np.array(polygon(ihouse1_for_stitch_points[:, 0], ihouse1_for_stitch_points[:, 1])).T\n",
        "# io.imshow(normalize_image(mask))\n",
        "# plt.show()  \n",
        "mask1 = polygon2mask(ihouse1_for_stitch.shape[:2], ihouse1_for_stitch_points[:, ::-1]).astype(np.uint8)\n",
        "mask2 = polygon2mask(ihouse2_for_stitch.shape[:2], ihouse2_for_stitch_points[:, ::-1]).astype(np.uint8)\n",
        "mask1_width = mask1.shape[1]\n",
        "gray_value = 0.8\n",
        "height = mask1.shape[0] \n",
        "width = mask1.shape[1]\n",
        "print(width)\n",
        "gray_mask_left = np.full((height, width*4//9), gray_value)\n",
        "black_mask_right = np.zeros((height, width*5//9), dtype=np.uint8)\n",
        "gray_mask_right = np.full((height, width*5//9), gray_value)\n",
        "black_mask_left = np.zeros((height, width*4//9), dtype=np.uint8)\n",
        "gray_right = np.concatenate((black_mask_left, gray_mask_right), axis=1)\n",
        "gray_left = np.concatenate((gray_mask_left, black_mask_right), axis=1)\n",
        "mask1_grayed = normalize_image(mask1)  \n",
        "mask1_grayed = np.where(mask1_grayed == 1.0, 0.4444444444444445, mask1_grayed)\n",
        "mask1_grayed = np.where(mask1_grayed == 0.0, 1.0, mask1_grayed)\n",
        "mask1_grayed = np.where(mask1_grayed == 0.4444444444444445, 0.0, mask1_grayed)\n",
        "mask2_grayed = normalize_image(mask2)   \n",
        "mask2_grayed = np.where(mask2_grayed == 1.0, 0.4444444444444445, mask2_grayed)\n",
        "mask2_grayed = np.where(mask2_grayed == 0.0, 1.0, mask2_grayed)\n",
        "mask2_grayed = np.where(mask2_grayed == 0.4444444444444445, 0.0, mask2_grayed) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 551,
      "metadata": {},
      "outputs": [],
      "source": [
        "room1 = io.imread('images/room1.png')\n",
        "room2 = io.imread('images/room2.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 552,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open (\"images/room1_room2.json\")\n",
        "json_data = json.load(f)\n",
        "room1_for_stitch_points = np.array(json_data['im1Points'])\n",
        "room2_for_stitch_points = np.array(json_data['im2Points'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 553,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lf/lddj8h6s3m3g8fkfp14cq4bw0000gn/T/ipykernel_71220/628019653.py:13: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  H_flatten = np.linalg.lstsq(A, B)[0]\n"
          ]
        }
      ],
      "source": [
        "roomH = computeH(room1_for_stitch_points, room2_for_stitch_points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 554,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done with color 0\n",
            "done with color 1\n",
            "done with color 2\n",
            "done with color 3\n"
          ]
        }
      ],
      "source": [
        "room1_warped = warp_image(room1, roomH, 'linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 555,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2da0d2b90>"
            ]
          },
          "execution_count": 555,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "io.imshow(normalize_image(room1_warped[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 532,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done with color 0\n",
            "done with color 1\n",
            "done with color 2\n",
            "done with color 3\n"
          ]
        }
      ],
      "source": [
        "room2_warped = warp_image(room2, roomH, 'linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 457,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(500, 699, 4)"
            ]
          },
          "execution_count": 457,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "room1_warped[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 533,
      "metadata": {},
      "outputs": [],
      "source": [
        "room1_warped_img = (room1_warped[0] * 255).astype(np.uint8)\n",
        "room2_warped_img = (room2_warped[0] * 255).astype(np.uint8) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 539,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2f1326990>"
            ]
          },
          "execution_count": 539,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "io.imshow(normalize_image(room2_warped[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 556,
      "metadata": {},
      "outputs": [],
      "source": [
        "room1_warped_img = normalize_image(room1_warped[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 606,
      "metadata": {},
      "outputs": [],
      "source": [
        "room1_aligned, room2_aligned = io.imread('room1_aligned.png'), io.imread('room2_aligned.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 560,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2f561a2d0>"
            ]
          },
          "execution_count": 560,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "io.imshow(room1_aligned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 607,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open (\"room1_aligned_room2_aligned (1).json\")\n",
        "json_data = json.load(f)\n",
        "room1_for_stitch_points = np.array(json_data['im1Points'])\n",
        "room2_for_stitch_points = np.array(json_data['im2Points'])\n",
        "mask1 = polygon2mask(room1_aligned.shape[:2], room1_for_stitch_points[:, ::-1]).astype(np.uint8)\n",
        "mask2 = polygon2mask(room2_aligned.shape[:2], room2_for_stitch_points[:, ::-1]).astype(np.uint8)\n",
        "mask1 = normalize_image(mask1)  \n",
        "mask2 = normalize_image(mask2)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 598,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  2,   0],\n",
              "       [167,   2],\n",
              "       [350,  40],\n",
              "       [340, 271],\n",
              "       [  1, 272]])"
            ]
          },
          "execution_count": 598,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "room1_for_stitch_points "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 486,
      "metadata": {},
      "outputs": [],
      "source": [
        "# io.imshow(mask1)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 608,
      "metadata": {},
      "outputs": [],
      "source": [
        "room1_for_stitch_resized = room1_aligned[:, :, :3]\n",
        "room2_for_stitch_resized = room2_aligned[:, :, :3]\n",
        "mask1_converted = cv2.convertScaleAbs(mask1, alpha=255)\n",
        "mask1_resized = cv2.cvtColor(mask1_converted, cv2.COLOR_GRAY2BGR)\n",
        "mask1_grayed_finalized = normalize_image(mask1_resized / 255.0) \n",
        "mask2_converted = cv2.convertScaleAbs(mask2, alpha=255)\n",
        "mask2_resized = cv2.cvtColor(mask2_converted, cv2.COLOR_GRAY2BGR)\n",
        "mask2_grayed_finalized = normalize_image(mask2_resized / 255.0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 609,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2f1342f90>"
            ]
          },
          "execution_count": 609,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "io.imshow(normalize_image(room2_for_stitch_resized))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 610,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2f1372450>"
            ]
          },
          "execution_count": 610,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "io.imshow(normalize_image(mask2_grayed_finalized))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 611,
      "metadata": {},
      "outputs": [],
      "source": [
        "room1_combined = combine_laplacian_stacks(room1_for_stitch_resized, room2_for_stitch_resized, 5, mask1_grayed_finalized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 612,
      "metadata": {},
      "outputs": [],
      "source": [
        "io.imshow(normalize_image(room1_combined))\n",
        "plt.show() "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
